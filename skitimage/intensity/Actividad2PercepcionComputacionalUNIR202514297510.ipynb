{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "9_Mv1_g-HRbo",
        "YPoyLZnvIthY",
        "XwzYHP47IlHp",
        "knp_R2i0I_U5"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/darwinyusef/20exHuggingFacePytorchTensorFlowSklearn/refs/heads/master/skitimage/intensity/presentacioncolab.png\" alt=\"Descripción de la imagen\" width=\"100%\" height=\"auto\">\n"
      ],
      "metadata": {
        "id": "x0-YVB2R_4aR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filtro media y Denoising basado en wavelets\n",
        "\n",
        "El código aplica dos técnicas de reducción de ruido a una imagen (`image`). Primero, utiliza un **filtro de media** (`cv2.medianBlur`) con un kernel de 3x3 para mitigar el ruido impulsivo o \"sal y pimienta\".\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/darwinyusef/20exHuggingFacePytorchTensorFlowSklearn/refs/heads/master/skitimage/intensity/mate1.JPG\" alt=\"median\" width=\"70%\" heigth=\"auto\"/>\n",
        "\n",
        "Luego, aplicamos un **denoising basado en wavelets** (`denoise_wavelet`) utilizando la transformada wavelet discreta para reducir el ruido gaussiano sin especificar parámetros incorrectos, seguido de una conversión a formato de 8 bits sin signo (`img_as_ubyte`).\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/darwinyusef/20exHuggingFacePytorchTensorFlowSklearn/refs/heads/master/skitimage/intensity/mate2walvet.JPG\" alt=\"median\" width=\"70%\" heigth=\"auto\"/>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9_Mv1_g-HRbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyWavelets\n",
        "!wget https://raw.githubusercontent.com/darwinyusef/20exHuggingFacePytorchTensorFlowSklearn/refs/heads/master/skitimage/intensity/salt-snoopy.png\n",
        "!wget https://raw.githubusercontent.com/darwinyusef/20exHuggingFacePytorchTensorFlowSklearn/refs/heads/master/skitimage/intensity/originalintensity.png\n",
        "!wget https://raw.githubusercontent.com/darwinyusef/20exHuggingFacePytorchTensorFlowSklearn/refs/heads/master/skitimage/intensity/moreintensity.jpeg"
      ],
      "metadata": {
        "id": "1HnulzDw9rwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDw5PRIt9IRc"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.restoration import denoise_wavelet\n",
        "from skimage import img_as_ubyte\n",
        "\n",
        "# Install PyWavelets if not already installed\n",
        "# !pip install PyWavelets # This line ensures PyWavelets is installed.\n",
        "\n",
        "# Cargar la imagen\n",
        "image_path = \"/content/salt-snoopy.png\"\n",
        "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Aplicar filtro de mediana para reducir ruido sal y pimienta\n",
        "median_filtered = cv2.medianBlur(image, 3)\n",
        "\n",
        "wavelet_denoised = denoise_wavelet(image, channel_axis=None, rescale_sigma=False)\n",
        "wavelet_denoised = img_as_ubyte(wavelet_denoised)\n",
        "\n",
        "# Mostrar imágenes comparativas nuevamente\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "axes[0].imshow(image, cmap=\"gray\")\n",
        "axes[0].set_title(\"Imagen Original\")\n",
        "axes[0].axis(\"off\")\n",
        "\n",
        "axes[1].imshow(wavelet_denoised, cmap=\"gray\")\n",
        "axes[1].set_title(\"Denoising con Wavelet\")\n",
        "axes[1].axis(\"off\")\n",
        "\n",
        "axes[2].imshow(median_filtered, cmap=\"gray\")\n",
        "axes[2].set_title(\"Filtro de Mediana\")\n",
        "axes[2].axis(\"off\")\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creación de mediana utilizando la categorización de la imagen de manera manual\n",
        "# Importar librerías necesarias\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Cargar la imagen en escala de grises\n",
        "# image_path = \"/salt-snoopy.png\"  # Incorrect path, likely missing content folder.\n",
        "image_path = \"/content/salt-snoopy.png\" # Update with full path.\n",
        "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Check if image loading was successful\n",
        "if image is None:\n",
        "    print(f\"Error: Could not load image from {image_path}. Please check the path.\")\n",
        "    exit()\n",
        "\n",
        "# Obtener dimensiones de la imagen\n",
        "height, width = image.shape\n",
        "\n",
        "# Crear una copia de la imagen para aplicar el filtro manualmente\n",
        "filtered_image = image.copy()\n",
        "\n",
        "# Aplicar filtro de mediana manual (ventana 3x3)\n",
        "for i in range(1, height - 1):\n",
        "    for j in range(1, width - 1):\n",
        "        # Extraer la categoria 3x3\n",
        "        neighborhood = [\n",
        "            image[i-1, j-1], image[i-1, j], image[i-1, j+1],\n",
        "            image[i, j-1], image[i, j], image[i, j+1],\n",
        "            image[i+1, j-1], image[i+1, j], image[i+1, j+1]\n",
        "        ]\n",
        "        # Reemplazar el píxel por la mediana de la categoria\n",
        "        filtered_image[i, j] = np.median(neighborhood)\n",
        "\n",
        "# Mostrar resultados\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axes[0].imshow(image, cmap=\"gray\")\n",
        "axes[0].set_title(\"Imagen con Ruido\")\n",
        "axes[0].axis(\"off\")\n",
        "\n",
        "axes[1].imshow(filtered_image, cmap=\"gray\")\n",
        "axes[1].set_title(\"Imagen Filtrada (Mediana Manual)\")\n",
        "axes[1].axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_jKgFJkqm1ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análisis de Textura\n",
        "El análisis de textura en imágenes permite describir patrones de variación en la intensidad de los píxeles, brindando información sobre rugosidad, uniformidad y contrastes locales. Se basa en estadísticas del histograma, filtrado espacial y modelos matemáticos. Es clave en visión por computadora para segmentación, reconocimiento de objetos y mejora de imágenes, siendo aplicado en áreas como medicina, inspección industrial y procesamiento de imágenes satelitales, procesamiento de imagenes para seguridad, aplicaciones de segmentación y clasificación de imagenes con machine learning y otros.\n",
        "\n",
        "## Momentos Estadísticos del Histograma\n",
        "El código en Colab analiza las características estadísticas del histograma de una imagen en escala de grises y en RGB. Primero, calcula el histograma normalizado, que representa la distribución de los niveles de intensidad en la imagen. Luego, extrae tres métricas clave:\n",
        "- Media: Indica el brillo promedio de la imagen.\n",
        "- Varianza: Mide el nivel de contraste o dispersión de los valores de intensidad.\n",
        "- Momento de orden n: Ayuda a describir la forma de la distribución de los niveles de intensidad.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/darwinyusef/20exHuggingFacePytorchTensorFlowSklearn/refs/heads/master/skitimage/intensity/mate3.JPG\" alt=\"median\" width=\"70%\" heigth=\"auto\"/>\n",
        "\n",
        "Estas métricas se calculan tanto para imágenes en escala de grises como para cada canal de color en imágenes RGB. Finalmente, el código genera una gráfica del histograma normalizado para visualizar la distribución de intensidades."
      ],
      "metadata": {
        "id": "YPoyLZnvIthY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "from skimage import io"
      ],
      "metadata": {
        "id": "4GNMkwN5Qt5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cambia esta ruta por la ruta de tu imagen\n",
        "image_path = '/content/originalintensity.png'\n",
        "image_path_intensity = '/content/moreintensity.png'\n",
        "# Cargar la imagen en escala de grises\n",
        "imagen = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "imagen_intensity = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "if imagen is None:\n",
        "    raise FileNotFoundError(f\"No se encontró la imagen en: {image_path}\")\n",
        "\n",
        "# Función para calcular el histograma\n",
        "def calcular_histograma(imagen):\n",
        "    hist, _ = np.histogram(imagen.flatten(), 256, [0, 256])\n",
        "    return hist"
      ],
      "metadata": {
        "id": "dF44XdyOImNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagen = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Calcular el histograma normalizado\n",
        "hist = cv2.calcHist([imagen], [0], None, [256], [0, 256])\n",
        "hist_norm = hist.ravel() / hist.sum()\n",
        "bins = np.arange(256)\n",
        "\n",
        "# Calcular estadísticas del histograma\n",
        "# Fórmulas:\n",
        "#   Media:    m = Σ(r_i * p(r_i))\n",
        "media = np.sum(bins * hist_norm)\n",
        "#   Varianza: s² = Σ((r_i - m)² * p(r_i))\n",
        "varianza = np.sum(((bins - media) ** 2) * hist_norm)\n",
        "#   Momento de orden n: m_n = Σ((r_i - m)^n * p(r_i))  todo * 3\n",
        "momento3 = np.sum(((bins - media) ** 3) * hist_norm)\n",
        "\n",
        "print(f\"Media: {media:.2f}, Varianza: {varianza:.2f}, Momento 3 (asimetría): {momento3:.2f}\")\n",
        "\n",
        "# Crear la figura con la imagen y el histograma\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Mostrar la imagen en escala de grises\n",
        "ax[0].imshow(imagen, cmap='gray')\n",
        "ax[0].set_title(\"Imagen en Escala de Grises\")\n",
        "ax[0].axis(\"off\")\n",
        "\n",
        "# Graficar el histograma normalizado\n",
        "ax[1].plot(bins, hist_norm, color='blue', lw=2)\n",
        "ax[1].set_title('Histograma Normalizado')\n",
        "ax[1].set_xlabel('Intensidad')\n",
        "ax[1].set_ylabel('Probabilidad')\n",
        "ax[1].grid()\n",
        "\n",
        "# Mostrar la figura\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h3zYEZm1NUSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagen_rgb = cv2.imread(image_path)\n",
        "imagen_rgb = cv2.cvtColor(imagen_rgb, cv2.COLOR_BGR2RGB)  # Convertir de BGR a RGB\n",
        "\n",
        "# Definir colores y nombres de canales\n",
        "colores = ('red', 'green', 'blue')\n",
        "canales = ('Rojo', 'Verde', 'Azul')\n",
        "\n",
        "# Crear la figura con la imagen y el histograma\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Mostrar la imagen original\n",
        "ax[0].imshow(imagen_rgb)\n",
        "ax[0].set_title(\"Imagen Original\")\n",
        "ax[0].axis(\"off\")\n",
        "\n",
        "# Graficar los histogramas normalizados en el segundo eje\n",
        "for i, color in enumerate(colores):\n",
        "    hist = cv2.calcHist([imagen_rgb], [i], None, [256], [0, 256])\n",
        "    hist_norm = hist.ravel() / hist.sum()  # Normalizar\n",
        "    ax[1].plot(hist_norm, color=color, label=f'Canal {canales[i]}')\n",
        "\n",
        "ax[1].set_title('Histogramas Normalizados RGB')\n",
        "ax[1].set_xlabel('Intensidad')\n",
        "ax[1].set_ylabel('Probabilidad')\n",
        "ax[1].legend()\n",
        "ax[1].grid()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JNgTN-vQPXlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Detección de Cambios de Intensidad Abruptos (Laplaciano)\n",
        "\n",
        "El código en Colab implementa la detección de cambios de intensidad abruptos en imágenes utilizando el operador Laplaciano. Este método resalta los bordes al identificar variaciones bruscas en la intensidad de los píxeles. Se aplican dos enfoques: uno que considera solo las categorias horizontales y verticales, y otro que también incluye los diagonales para detectar cambios más complejos. Esta técnica es clave en visión por computadora para segmentación, detección de bordes y análisis de texturas.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/darwinyusef/20exHuggingFacePytorchTensorFlowSklearn/refs/heads/master/skitimage/intensity/mate4.JPG\" alt=\"median\" width=\"70%\" heigth=\"auto\"/>"
      ],
      "metadata": {
        "id": "XwzYHP47IlHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fórmula sin diagonales:\n",
        "#   ∇²f(x,y) = f(x+1,y) + f(x-1,y) + f(x,y+1) + f(x,y-1) - 4f(x,y)\n",
        "# Máscara: [[0, 1, 0],\n",
        "#          [1, -4, 1],\n",
        "#          [0, 1, 0]]\n",
        "mask1 = np.array([[0, 1, 0],\n",
        "                  [1, -4, 1],\n",
        "                  [0, 1, 0]], dtype=np.float32)\n",
        "laplaciano1 = cv2.filter2D(imagen, ddepth=cv2.CV_64F, kernel=mask1)\n",
        "laplaciano1 = np.uint8(np.absolute(laplaciano1))\n",
        "\n",
        "# Fórmula con diagonales:\n",
        "#   ∇²f(x,y) = f(x+1,y) + f(x-1,y) + f(x,y+1) + f(x,y-1) +\n",
        "#              f(x+1,y+1) + f(x+1,y-1) + f(x-1,y+1) + f(x-1,y-1) - 8f(x,y)\n",
        "# Máscara: [[1, 1, 1],\n",
        "#          [1, -8, 1],\n",
        "#          [1, 1, 1]]\n",
        "mask2 = np.array([[1, 1, 1],\n",
        "                  [1, -8, 1],\n",
        "                  [1, 1, 1]], dtype=np.float32)\n",
        "laplaciano2 = cv2.filter2D(imagen_intensity, ddepth=cv2.CV_64F, kernel=mask2)\n",
        "laplaciano2 = np.uint8(np.absolute(laplaciano2))\n",
        "\n",
        "# Mostrar Laplaciano\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 3, 1), plt.imshow(imagen, cmap='gray'), plt.title('Imagen Original')\n",
        "plt.subplot(1, 3, 2), plt.imshow(laplaciano1, cmap='gray'), plt.title('Laplaciano sin diagonales')\n",
        "plt.subplot(1, 3, 3), plt.imshow(laplaciano2, cmap='gray'), plt.title('Laplaciano con diagonales')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Obtener histogramas\n",
        "hist_fuente = calcular_histograma(imagen)\n",
        "hist_referencia = calcular_histograma(imagen_intensity)\n",
        "\n",
        "# Mostrar histogramas\n",
        "plt.figure(figsize=(16, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(hist_fuente, color='blue')\n",
        "plt.title('Histograma - Imagen Fuente')\n",
        "plt.xlabel('Intensidad de píxeles')\n",
        "plt.ylabel('Frecuencia')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(hist_referencia, color='red')\n",
        "plt.title('Histograma - Imagen referencia')\n",
        "plt.xlabel('Intensidad de píxeles')\n",
        "plt.ylabel('Frecuencia')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2EhOHEjEIqcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Procesamiento Morfológico para verificación de anomalias superficiales de la imagen e inspección de Formas\n",
        "\n",
        "El código realiza un análisis de imágenes aplicando procesamiento morfológico y Transformada Discreta de Fourier (DFT). Primero, usa técnicas como erosión, dilatación, apertura y cierre para mejorar la imagen y eliminar ruido. Luego, extrae el contorno principal y analiza su forma mediante la DFT, que convierte la información del contorno en frecuencias para detectar anomalías y patrones geométricos. Esto permite evaluar deformaciones y características superficiales en la imagen, facilitando la inspección visual y la detección de irregularidades.\n",
        "\n",
        "Se utiliza para mejorar la imagen antes del análisis.\n",
        "\n",
        "- Erosión elimina pequeños detalles y reduce los objetos.\n",
        "- Dilatación expande los objetos resaltando bordes.\n",
        "- Apertura elimina ruido mientras mantiene las formas principales.\n",
        "- Cierre rellena pequeños huecos en los objetos.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/darwinyusef/20exHuggingFacePytorchTensorFlowSklearn/refs/heads/master/skitimage/intensity/mate5.JPG\" alt=\"median\" width=\"70%\" heigth=\"auto\"/>\n",
        "\n",
        "## Descriptores de Contorno (Transformada Discreta de Fourier - DFT)\n",
        "\n",
        "Representa el contorno en coordenadas complejas.\n",
        "Convierte la información del espacio en frecuencias para detectar patrones y anomalías.\n",
        "Permite comparar formas y evaluar deformaciones en la imagen.\n",
        "\n",
        "Estos métodos combinados mejoran la inspección visual y la detección automática de irregularidades en imágenes.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/darwinyusef/20exHuggingFacePytorchTensorFlowSklearn/refs/heads/master/skitimage/intensity/mate6.JPG\" alt=\"median\" width=\"70%\" heigth=\"auto\"/>"
      ],
      "metadata": {
        "id": "knp_R2i0I_U5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fórmulas:\n",
        "#   Erosión:    A ⊖ B = {z | (B)_z ⊆ A}\n",
        "#   Dilatación: A ⊕ B = {z | (B̂)_z ∩ A ≠ ∅}\n",
        "#   Apertura:   A ∘ B = (A ⊖ B) ⊕ B\n",
        "#   Cierre:     A • B = (A ⊕ B) ⊖ B\n",
        "\n",
        "# Puede hacer el cambio para pruebas entre una imagen normal y una más intensa\n",
        "img =  imagen_intensity # imagen\n",
        "_, binaria = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
        "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
        "erosionada = cv2.erode(binaria, kernel, iterations=1)\n",
        "dilatada = cv2.dilate(binaria, kernel, iterations=1)\n",
        "apertura = cv2.morphologyEx(binaria, cv2.MORPH_OPEN, kernel)\n",
        "cierre = cv2.morphologyEx(binaria, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "# Fórmula:\n",
        "#   Sea s(k) = x(k) + j y(k) para k=0,...,K-1, entonces:\n",
        "#   a(u) = (1/K) Σ s(k) * exp(-j2πuk/K)\n",
        "# Extraemos el contorno principal de la imagen binaria\n",
        "contornos, _ = cv2.findContours(binaria, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "if not contornos:\n",
        "    raise ValueError(\"No se encontraron contornos en la imagen\")\n",
        "contorno = max(contornos, key=cv2.contourArea)\n",
        "contorno = contorno[:, 0, :]  # Removemos la dimensión extra\n",
        "\n",
        "# Convertir puntos del contorno a números complejos\n",
        "s = contorno[:, 0] + 1j * contorno[:, 1]\n",
        "K = len(s)\n",
        "a = np.fft.fft(s) / K  # Coeficientes de Fourier normalizados\n",
        "\n",
        "plt.figure(figsize=(15, 8))\n",
        "plt.subplot(2, 3, 1), plt.imshow(binaria, cmap='gray'), plt.title('Imagen Binaria Original')\n",
        "plt.subplot(2, 3, 2), plt.imshow(erosionada, cmap='gray'), plt.title('Erosión')\n",
        "plt.subplot(2, 3, 3), plt.imshow(dilatada, cmap='gray'), plt.title('Dilatación')\n",
        "plt.subplot(2, 3, 4), plt.imshow(apertura, cmap='gray'), plt.title('Apertura')\n",
        "plt.subplot(2, 3, 5), plt.imshow(cierre, cmap='gray'), plt.title('Cierre')\n",
        "plt.subplot(2, 3, 6), plt.stem(np.abs(a)), plt.title('Magnitud de Coeficientes Fourier del Contorno'), plt.xlabel('Frecuencia'), plt.ylabel('Magnitud')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9YksPospI_44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradiente para Detección de Bordes Anómalos y gestion de filtros Kernel y otros ( SOBEL )\n",
        "\n",
        "1. Este código implementa un procesamiento de imágenes para detectar bordes anómalos y aplicar diferentes filtros. Utiliza el operador Sobel para resaltar bordes en direcciones horizontal y vertical, permitiendo identificar cambios bruscos en la intensidad de la imagen.\n",
        "\n",
        "2. Además, se aplican múltiples filtros de procesamiento, como enfoque, desenfoque, detección de bordes, realce de detalles y suavizado. Estos filtros ayudan a mejorar la calidad visual y destacar características importantes de la imagen.\n",
        "\n",
        "3. El código almacena los resultados de cada filtro y los aplica sobre la imagen original para obtener diferentes versiones procesadas, facilitando la inspección de detalles y la identificación de anomalías.\n",
        "<img src=\"https://raw.githubusercontent.com/darwinyusef/20exHuggingFacePytorchTensorFlowSklearn/refs/heads/master/skitimage/intensity/mate7.JPG\" alt=\"median\" width=\"70%\" heigth=\"auto\"/>\n",
        "\n",
        "El código define una serie de filtros utilizados en visión por computadora:\n",
        "\n",
        "- Enfoque: Resalta detalles aumentando el contraste en los bordes.\n",
        "- Desenfoque: Suaviza la imagen reduciendo el ruido.\n",
        "- Sobel X / Y: Detecta bordes en direcciones específicas.\n",
        "- Filtro Gaussiano: Reduce ruido preservando estructuras importantes.\n",
        "- Sharpen (Afilado): Resalta detalles y mejora nitidez.\n",
        "- Repujado: Simula relieve en la imagen.\n",
        "- Detección de bordes: Encuentra cambios abruptos en la intensidad.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CQYbHVWPTXvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fórmulas:\n",
        "#   Aproximación 1: M(x,y) ≈ |g_x| + |g_y|\n",
        "#   Aproximación 2: M(x,y) = sqrt(g_x^2 + g_y^2)\n",
        "# Cálculo de derivadas (Ejemplo con máscaras de Sobel)\n",
        "# Puede hacer el cambio para pruebas entre una imagen normal y una más intensa\n",
        "img = imagen_intensity # imagen\n",
        "g_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)\n",
        "g_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3)\n",
        "magnitud1 = np.abs(g_x) + np.abs(g_y)\n",
        "magnitud2 = np.sqrt(g_x**2 + g_y**2)\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,3,1), plt.imshow(img, cmap='gray'), plt.title('Imagen Original')\n",
        "plt.subplot(1,3,2), plt.imshow(magnitud1, cmap='gray'), plt.title('Gradiente: |g_x|+|g_y|')\n",
        "plt.subplot(1,3,3), plt.imshow(magnitud2, cmap='gray'), plt.title('Gradiente: sqrt(g_x²+g_y²)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ps7oupv9JKbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the image was loaded successfully\n",
        "if imagen is None:\n",
        "    print(\"Error: Could not load image. Please check the file path and name.\")\n",
        "    exit() # or handle the error in another way\n",
        "\n",
        "# Definir un kernel de detección de bordes\n",
        "kernel = np.array([[0, 1, 0],\n",
        "                   [1, -4, 1],\n",
        "                   [0, 1, 0]])\n",
        "\n",
        "# Aplicar el filtro a la imagen\n",
        "imagen_filtrada = cv2.filter2D(imagen, -1, kernel)\n",
        "\n",
        "# Mostrar la imagen original y la imagen filtrada\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(imagen, cmap=\"gray\")\n",
        "plt.title(\"Imagen Original\", fontsize=14, fontweight=\"bold\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(imagen_filtrada, cmap=\"gray\")\n",
        "plt.title(\"Imagen con Detección de Bordes\", fontsize=14, fontweight=\"bold\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2bEB3zR5TsaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir los filtros\n",
        "filtros = {\n",
        "    \"Enfoque\": np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]]),\n",
        "    \"Desenfoque\": np.ones((3, 3), np.float32) / 9,\n",
        "    \"Sobel X\": np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]),\n",
        "    \"Sobel Y\": np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]]),\n",
        "    \"Filtro Gaussiano\": cv2.getGaussianKernel(3, 1) @ cv2.getGaussianKernel(3, 1).T,\n",
        "    \"Sharpen\": np.array([[1, -2, 1], [-2, 5, -2], [1, -2, 1]]),\n",
        "    \"Repujado\": np.array([[-2, -1, 0], [-1, 1, 1], [0, 1, 2]]),\n",
        "    \"Detección de bordes\": np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]]),\n",
        "    \"Filtro Sobel X\": np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]),\n",
        "    \"Filtro Sobel Y\": np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]]),\n",
        "    \"Filtro Sharpen\": np.array([[1, -2, 1], [-2, 5, -2], [1, -2, 1]]),\n",
        "    \"Filtro Norte\": np.array([[1, 1, 1], [1, -2, 1], [-1, -1, -1]]),\n",
        "    \"Filtro Este\": np.array([[-1, 1, 1], [-1, -2, 1], [-1, 1, 1]]),\n",
        "    \"Filtro Sharpen\": np.array([[1, -2, 1], [-2, 5, -2], [1, -2, 1]]),\n",
        "    \"Filtro Norte\": np.array([[1, 1, 1], [1, -2, 1], [-1, -1, -1]]),\n",
        "    \"Filtro Gaussiano\": np.array([\n",
        "        [1, 2, 3, 2, 1],\n",
        "        [2, 7, 11, 7, 2],\n",
        "        [3, 11, 17, 11, 3],\n",
        "        [2, 7, 11, 7, 2],\n",
        "        [1, 2, 3, 2, 1]\n",
        "    ]) / 115  # Normalización para mantener la intensidad\n",
        "}\n",
        "\n",
        "\n",
        "# Aplicar filtros y almacenar resultados\n",
        "resultados = {\"Imagen Original\": imagen}\n",
        "for nombre, kernel in filtros.items():\n",
        "    resultados[nombre] = cv2.filter2D(imagen, -1, kernel)\n",
        "\n",
        "# Mostrar todas las imágenes en una sola figura\n",
        "fig, axes = plt.subplots(4, 4, figsize=(15, 12))\n",
        "\n",
        "for ax, (nombre, img) in zip(axes.flat, resultados.items()):\n",
        "    ax.imshow(img, cmap=\"gray\")\n",
        "    ax.set_title(nombre, fontsize=10, fontweight=\"bold\")\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j0DiHMCQUBAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Referencia Bibliográfica:**\n",
        "\n",
        "* Bradski, G., & Kaehler, A. (2008). *Learning OpenCV: Computer vision with the OpenCV library*. O'Reilly Media.\n",
        "* Denoising basado en wavelets Gonzalez, R. C. (© 2008 by Pearson Education, Inc.). *Digital Image Processing* (3rd ed.). University of Tennessee. 153 - 158 Chapter 7\n",
        "\n",
        "* Chapter 3 ■ Intensity Transformations and Spatial Filtering\n",
        "Denoising basado en wavelets Gonzalez, R. C. (© 2008 by Pearson Education, Inc.). *Digital Image Processing* (3rd ed.). University of Tennessee. 486 - 490 Chapter 3 ■ Wavelets and Multiresolution Processing\n",
        "\n",
        "* Laplacian Theory\n",
        "Gonzalez, R. C., & Woods, R. E. (2008). Laplacian operator and its applications. In Digital image processing (3rd ed., pp. 190, 249, 698). Pearson Education.\n",
        "\n",
        "* Mathematics Behind the Median Filter\n",
        "Gonzalez, R. C., & Woods, R. E. (2008). Median filtering and order-statistic filters. In Digital image processing (3rd ed., pp. 175-185). Pearson Education.\n",
        "\n",
        "* Mathematics Behind Wavelet-Based Denoising\n",
        "Gonzalez, R. C., & Woods, R. E. (2008). Wavelets and multiresolution processing. In Digital image processing (3rd ed., pp. 462-493). Pearson Education.\n",
        "\n",
        "* Aprendizaje de matplotlib, visión por computadora y anomaly analytics kernels, https://chatgpt.com/c/67e22bde-19bc-800f-9e50-a8f160c123cb.\n",
        "\n",
        "* Curso: \"Python para visión artificial\"\n",
        "Instructor desconocido. (s.f.). Python para visión artificial. Udemy. Recuperado de https://www.udemy.com/course/python-para-vision-artificial/\n",
        "\n",
        "* Curso: \"Modern Computer Vision\"\n",
        "Instructor desconocido. (s.f.). Modern Computer Vision. Udemy. Recuperado de https://www.udemy.com/course/modern-computer-vision/\n",
        "\n",
        "* Video: \"Curso de OpenCV y Python desde cero - Detección de bordes y contornos\"\n",
        "Programación ATS. (2021, 15 de marzo). Curso de OpenCV y Python desde cero - Detección de bordes y contornos [Video]. YouTube. Recuperado de https://www.youtube.com/watch?v=JzMnGKmsiJE&t=3453s\n",
        "\n",
        "* Video: \"Introducción a la Visión por Computador con OpenCV y Python\"\n",
        "AI for Everyone. (2020, 10 de junio). Introducción a la Visión por Computador con OpenCV y Python [Video]. YouTube. Recuperado de https://www.youtube.com/watch?v=KVd_bzsvau0&t=7s\n",
        "\n",
        "* Video: \"Detección de Anomalías en Series Temporales con Python\"\n",
        "Data Science en Español. (2021, 22 de agosto). Detección de Anomalías en Series Temporales con Python [Video]. YouTube. Recuperado de https://www.youtube.com/watch?v=xmyLLHJRndg\n",
        "\n",
        "* Video: \"Análisis de Imágenes Satelitales con Python y OpenCV\"\n",
        "Geospatial Python. (2020, 5 de mayo). Análisis de Imágenes Satelitales con Python y OpenCV [Video]. YouTube. Recuperado de https://www.youtube.com/watch?v=01sAkU_NvOY&t=15s\n",
        "\n",
        "* Video: \"Implementación de Redes Neuronales Convolucionales en TensorFlow\"\n",
        "Deep Learning Academy. (2021, 12 de septiembre). Implementación de Redes Neuronales Convolucionales en TensorFlow [Video]. YouTube. Recuperado de https://www.youtube.com/watch?v=I7lCpTOfxF4&t=246s\n",
        "\n",
        "* Video: \"Tutorial de OpenCV: Procesamiento de Imágenes en Tiempo Real\"\n",
        "Tech with Tim. (2019, 20 de noviembre). Tutorial de OpenCV: Procesamiento de Imágenes en Tiempo Real [Video]. YouTube. Recuperado de https://www.youtube.com/watch?v=oXlwWbU8l2o&t=2399s\n",
        "\n",
        "* Video: \"Análisis de Componentes Principales (PCA) en Python\"\n",
        "StatQuest with Josh Starmer. (2020, 15 de abril). Análisis de Componentes Principales (PCA) en Python [Video]. YouTube. Recuperado de https://www.youtube.com/watch?v=qUf_pJ4OHH0&t=187s\n",
        "\n",
        "* Video: \"Clasificación de Imágenes con Scikit-Learn y Python\"\n",
        "Machine Learning with Phil. (2021, 8 de julio). Clasificación de Imágenes con Scikit-Learn y Python [Video]. YouTube. Recuperado de https://www.youtube.com/watch?v=rJhe6QjQ120&t=133s\n",
        "\n",
        "* Curso: \"Curso Profesional de Computer Vision con TensorFlow\"\n",
        "Vera, A. (s.f.). Curso Profesional de Computer Vision con TensorFlow. Platzi. Recuperado de https://platzi.com/cursos/computer-vision-tensorflow/\n",
        "\n",
        "* Curso: \"Curso de Detección y Segmentación de Objetos con TensorFlow\"\n",
        "Paniego Blanco, S. (s.f.). Curso de Detección y Segmentación de Objetos con TensorFlow. Platzi. Recuperado de https://platzi.com/cursos/tensorflow-objetos/\n",
        "\n",
        "* Curso: \"Curso de Experimentación en Machine Learning con Hugging Face\"\n",
        "Espejel, O. (s.f.). Curso de Experimentación en Machine Learning con Hugging Face. Platzi. Recuperado de https://platzi.com/cursos/demos-machine-learning/\n",
        "\n",
        "* Ejemplificación de estructuras de codigo python basados en la generación de modelos matematicos usando python, cv2 y skitimage pillow y pruebas con images en tiempo real con webassemby generado directamente por la maquina.\n",
        "OpenAI. (2023). ChatGPT [Modelo de lenguaje de gran tamaño]. Recuperado de https://chatgpt.com/\n",
        "\n",
        "* Autor desconocido. (s.f.). Digital Image Processing - Lecture #6: Image Restoration [Presentación de diapositivas]. BIOMISA. Recuperado de https://biomisa.org/uploads/2013/07/Lect-6%20Restoration.pdf"
      ],
      "metadata": {
        "id": "Px_my-GcXYpo"
      }
    }
  ]
}