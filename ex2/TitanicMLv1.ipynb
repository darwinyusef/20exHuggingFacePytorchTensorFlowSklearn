{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPbPeHLRdQ7ZyvQhdg6RQL7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darwinyusef/20exHuggingFacePytorchTensorFlowSklearn/blob/master/ex2/TitanicMLv1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy scikit-learn\n",
        "!pip install imbalanced-learn\n"
      ],
      "metadata": {
        "id": "hK_EIzxHOzNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Importamos las librerías necesarias\n",
        "import pandas as pd  # Para manejar datos en forma de DataFrame\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler  # Para codificación y normalización\n",
        "from sklearn.model_selection import train_test_split  # Para dividir los datos en entrenamiento y prueba\n",
        "from sklearn.ensemble import RandomForestClassifier  # Modelo de clasificación basado en árboles\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix # Para evaluar el rendimiento del modelo\n",
        "from imblearn.under_sampling import RandomUnderSampler  # Para balanceo de clases en el dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "F6gSU-upOsXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar datos\n",
        "data = pd.read_csv('/content/titanic.csv')\n",
        "data"
      ],
      "metadata": {
        "id": "Q4Rxwbs9O8M1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the original column names are 'name' and 'fare' (case-sensitive)\n",
        "titanic = data.drop(['name', 'Fare'], axis=1, errors='ignore')\n",
        "# axis=1 specifies dropping columns, errors='ignore' prevents error if columns not found\n",
        "titanic"
      ],
      "metadata": {
        "id": "m3BzjuvKPOKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic.shape"
      ],
      "metadata": {
        "id": "0CPxUDEVPZx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic.head()"
      ],
      "metadata": {
        "id": "BbwJZDqlPgKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjcvKq8TOPt2"
      },
      "outputs": [],
      "source": [
        "# @markdown **Limpieza de datos**\n",
        "titanic.dropna(inplace=True)  # @markdown Eliminamos filas con valores nulos para evitar problemas en el entrenamiento\n",
        "\n",
        "# @markdown **Codificación de variables categóricas**\n",
        "# @markdown Convertimos la columna 'Sex' (que contiene valores 'male' y 'female') en valores numéricos (0 y 1)\n",
        "titanic['Sex'] = LabelEncoder().fit_transform(titanic['Sex'])\n",
        "\n",
        "# @markdown **Definimos las variables predictoras (X) y la variable objetivo (y)**\n",
        "X = titanic.drop(columns=['Survived'])  # Eliminamos la columna 'Survived' para usar el resto como características\n",
        "y = titanic['Survived']  # La columna 'Survived' será la variable objetivo (1 = sobrevivió, 0 = no sobrevivió)\n",
        "\n",
        "# @markdown **Balanceo de clases con UnderSampling**\n",
        "# @markdown Este paso es útil si la cantidad de sobrevivientes y no sobrevivientes está desbalanceada\n",
        "undersampler = RandomUnderSampler(random_state=42)  # @markdown Creamos un objeto para realizar el submuestreo\n",
        "X, y = undersampler.fit_resample(X, y)  # @markdown Aplicamos el submuestreo para equilibrar las clases\n",
        "\n",
        "# @markdown **División del dataset en entrenamiento y prueba**\n",
        "# @markdown Separamos el conjunto de datos en un 80% para entrenamiento y 20% para prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# @markdown **Normalización de los datos**\n",
        "scaler = StandardScaler()  # @markdown Creamos un objeto StandardScaler para normalizar los datos\n",
        "X_train = scaler.fit_transform(X_train)  # @markdown Ajustamos el escalador en los datos de entrenamiento y los transformamos\n",
        "X_test = scaler.transform(X_test)  # @markdown Usamos el mismo escalador para transformar los datos de prueba\n",
        "\n",
        "# @markdown **Entrenamiento del modelo**\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)  # @markdown Creamos el modelo de bosque aleatorio con 100 árboles\n",
        "model.fit(X_train, y_train)  # @markdown Entrenamos el modelo con los datos de entrenamiento\n",
        "\n",
        "# @markdown**Predicción en los datos de prueba**\n",
        "y_pred = model.predict(X_test)  # @markdown Generamos predicciones con el modelo entrenado\n",
        "\n",
        "# @markdown **Evaluación del modelo**\n",
        "accuracy = accuracy_score(y_test, y_pred)  # @markdown Calculamos la precisión comparando predicciones con valores reales\n",
        "print(f'Precisión del modelo: {accuracy:.4f}') # @markdown Mostramos la precisión del modelo en la consola\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importancia de características\n",
        "feature_importances = model.feature_importances_\n",
        "feature_names = X.columns\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.barplot(x=feature_importances, y=feature_names)\n",
        "plt.xlabel('Importancia')\n",
        "plt.ylabel('Características')\n",
        "plt.title('Importancia de las Características')\n",
        "plt.show()\n",
        "\n",
        "# Matriz de Confusión\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['No Sobrevivió', 'Sobrevivió'], yticklabels=['No Sobrevivió', 'Sobrevivió'])\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Real')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "u7ks2qyQa6n_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener la importancia de características del modelo\n",
        "importances = model.feature_importances_\n",
        "feature_names = X.columns\n",
        "\n",
        "# Crear la figura\n",
        "fig, axes = plt.subplots(2, 1, figsize=(8, 12))\n",
        "\n",
        "# Gráfica de Importancia de Características\n",
        "sns.barplot(x=importances, y=feature_names, ax=axes[0], palette=\"Blues_r\", edgecolor=\"black\")\n",
        "axes[0].set_xlabel(\"Importancia\", fontsize=12)\n",
        "axes[0].set_ylabel(\"Características\", fontsize=12)\n",
        "axes[0].set_title(\"Importancia de las Características\", fontsize=14, fontweight=\"bold\")\n",
        "\n",
        "# Agregar etiquetas de valores en cada barra\n",
        "for i, v in enumerate(importances):\n",
        "    axes[0].text(v + 0.01, i, f\"{v:.2f}\", color=\"black\", va=\"center\", fontsize=11)\n",
        "\n",
        "# Matriz de Confusión\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "conf_matrix_percentage = conf_matrix.astype(\"float\") / conf_matrix.sum(axis=1)[:, np.newaxis] * 100\n",
        "\n",
        "# Crear mapa de calor de la matriz de confusión\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", linewidths=1, linecolor=\"black\",\n",
        "            xticklabels=[\"No Sobrevivió\", \"Sobrevivió\"], yticklabels=[\"No Sobrevivió\", \"Sobrevivió\"], ax=axes[1])\n",
        "axes[1].set_xlabel(\"Predicción\", fontsize=12)\n",
        "axes[1].set_ylabel(\"Real\", fontsize=12)\n",
        "axes[1].set_title(\"Matriz de Confusión\", fontsize=14, fontweight=\"bold\")\n",
        "\n",
        "# Ajustar el diseño\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OViHN5oMcYTA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}